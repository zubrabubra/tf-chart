{{- $relname := .Values.global.relname -}}
{{- $storname := .Values.storage.name -}}
{{- $repo := .Values.tfCluster.image.repo -}}
{{- $image := .Values.tfCluster.image.name -}}
{{- $tagGpu := .Values.tfCluster.image.dockerTagGpu -}}
{{- $tagCpu := .Values.tfCluster.image.dockerTagCpu -}}
{{- $port := .Values.tfCluster.service.internalPort -}}
{{- $nbGpu := .Values.tfCluster.settings.nbGpuPerNode -}}
{{- $isGpu := .Values.tfCluster.settings.isGpu -}}
{{- $dataset := .Values.tfCluster.settings.dataset -}}
{{- $resources := .Values.tfCluster.resources -}}

---
# Defining a generic configuration file for the cluster
apiVersion: v1
kind: ConfigMap
metadata:
  name: tensorflowjob1-cluster-config
data:
  clusterconfig: >
        {
        {{- range $job, $nb := .Values.tfCluster.settings.jobs }}
          {{ $job | quote }}: [
          {{ range $i, $e := until (int $nb) | default 8 }}
            "{{ $job }}-{{$i}}.{{ $relname }}.svc.cluster.local:8080",
          {{ end }}
              ],
        {{- end }}
        }
---
{{- range $job, $nb := .Values.tfCluster.settings.jobs }}
{{ range $i, $e := until (int $nb) | default 8 }}
# Definiting a scalable cluster
apiVersion: batch/v1
kind: Job
metadata:
  name: {{ $job }}-{{$i}}
spec:
#  replicas: 1
#  selector:
#    matchLabels:
#      job: {{ $job }}
#      task: t{{$i}}
  template:
    metadata:
      labels:
        job: {{ $job }}
        task: t{{$i}}
    spec:
      containers:
      - name: tf-grpc-server
        {{ if eq $job "worker" }}
        image: {{ $repo }}/{{ $image }}
        {{ else }}
        image: {{ $repo }}/{{ $image }}cpu
        {{ end }}
        securityContext:
          privileged: true
        ports:
        - name: grpc-server
          containerPort: {{ $port }}
        env:
        - name: POD_NAME
          value: {{ $job }}-{{ $i }}
        - name: DATA_DIR
          value: /var/tensorflow/flowers/
        - name: LD_LIBRARY_PATH
          value: "$LD_LIBRARY_PATH:/usr/lib/nvidia:/usr/lib/cuda"
        - name: CLUSTER_CONFIG
          valueFrom:
            configMapKeyRef:
              name: tensorflowjob1-cluster-config
              key: clusterconfig
        volumeMounts:
        - name: {{ $storname }}
          mountPath: /efs/tensorflow
        {{ if eq $job "worker" }}
        - mountPath: /dev/nvidia0
          name: nvidia0
        - mountPath: /dev/nvidiactl
          name: nvidiactl
        - mountPath: /dev/nvidia-uvm
          name: nvidia-uvm
        - mountPath: /usr/local/nvidia/bin
          name: bin
        - mountPath: /usr/lib/nvidia
          name: lib
        - mountPath: /usr/lib/cuda
          name: libcuda
        {{ end }}
      restartPolicy: Never
      volumes:
      - name: {{ $storname }}
        persistentVolumeClaim:
          claimName: {{ $storname }}
       {{ if eq $job "worker" }}
      - name: nvidia0
        hostPath: 
          path: /dev/nvidia0
      - name: nvidiactl
        hostPath: 
          path: /dev/nvidiactl
      - name: nvidia-uvm
        hostPath: 
          path: /dev/nvidia-uvm
      - name: bin
        hostPath: 
          path: /usr/lib/nvidia-375/bin
      - name: lib
        hostPath: 
          path: /usr/lib/nvidia-375
      - name: libcuda
        hostPath: 
          path: /usr/lib/x86_64-linux-gnu
      {{ end }}
      {{ if eq $job "worker" }}
      nodeSelector:
        type: gpu{{ $i }}
      affinity:
          podAntiAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                - key: job
                  operator: In
                  values:
                  - worker
              topologyKey: workers
      {{ else }}
      nodeSelector:
        type: cpu
      {{ end }}
      
---
{{ end }}
{{- end }}
